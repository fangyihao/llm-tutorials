{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ee0fdb-8bb7-4311-a8d2-78329c282c6f",
   "metadata": {},
   "source": [
    "# Advanced Product Mapping \n",
    "\n",
    "Author: Yihao Fang, Ph.D.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "The stakeholder operates convenience-store-like markets and receives weekly shipments from suppliers, including an assortment of newly introduced items. Two CSV files are provided: one containing the stakeholder’s internal product list, and another containing the suppliers’ external product list.\n",
    "\n",
    "### Objective\n",
    "The existing method of mapping the two product lists is slow and relies on manual effort. The objective is to analyze the datasets and design an intelligent, automated system to match external products with internal items. The solution should incorporate prompt engineering as part of the technology stack. It is important to ensure that matches are exact, requiring identical product manufacturer, name, and size.\n",
    "\n",
    "### Examples\n",
    "Here are a few examples of correct and wrong matches:\n",
    "\n",
    "#### Correct Matches:\n",
    "|External_Product_Name|Internal_Product_Name|\n",
    "|---|---|\n",
    "|DIET LIPTON GREEN TEA W/ CITRUS 20 OZ|Lipton Diet Green Tea with Citrus (20oz)|\n",
    "|CH-CHERRY CHS CLAW DANISH 4.25 OZ|Cloverhill Cherry Cheese Bearclaw Danish (4.25oz)|\n",
    "\n",
    "#### Wrong Matches:\n",
    "|External_Product_Name|Internal_Product_Name|\n",
    "|---|---|\n",
    "|Hersheys Almond Milk Choco 1.6 oz|Hersheys Milk Chocolate with Almonds (1.85oz)|\n",
    "|COOKIE PEANUT BUTTER 2OZ|Famous Amos Peanut Butter Cookie (2oz)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee22bf2a-c720-481f-80c9-e2946c78aa92",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "The two approaches differ significantly in methodology, cost-efficiency, and complexity. The BM25 Retriever Augmented Llama 3.2 approach relies on a sophisticated pipeline combining probabilistic retrieval with advanced NLP techniques and the Llama 3.2 language model. It employs retrieval-augmented generation, chain-of-thought reasoning, and self-consistency mechanisms to ensure accurate and interpretable product mapping. This open-source approach is far more cost-efficient compared to proprietary ChatGPT solutions, making it attractive for budget-conscious applications. \n",
    "\n",
    "In contrast, the ChatGPT o1-mini approach simplifies intricate tasks by focusing on an iterative and modular workflow that leverages the reasoning capabilities of ChatGPT. By eschewing complex pipelines in favor of streamlined logic and iterative refinement, it achieves robust and scalable results with reduced implementation complexity. While the open-source approach offers advanced customization and interpretability, the proprietary ChatGPT method emphasizes ease of use and simplicity, making it more accessible for use cases requiring rapid deployment and minimal setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb8a48-5bb3-4f70-bc59-ad5eaaa77656",
   "metadata": {},
   "source": [
    "### Approach One: BM25 Retriever Augmented Llama 3.2 Large Language Model (Open Source)\n",
    "This approach implements a pipeline to match external product names with internal product names using a combination of advanced NLP techniques and probabilistic models. It begins by preprocessing internal product names with <b>SentencePiece subword encoding</b> (Kudo, T., & Richardson, J., 2018), ensuring robust tokenization for downstream tasks. External products are mapped to internal products by first retrieving the top K most relevant candidates using the <b>BM25 retrieval model</b> (Robertson, S., & Zaragoza, H., 2009), which ranks potential matches based on tokenized similarity. The matching process relies on the <b>Llama 3.2 large language model (LLM)</b> (Touvron, H., Lavril et al., 2023), which leverages <b>few-shot prompting</b> to provide structured examples and guide the model's behavior. Additionally, <b>chain-of-thought reasoning</b> (Wei, J. et al., 2022) is employed, requiring the LLM to provide a detailed rationale for its match or mismatch decisions, improving interpretability and reliability.\n",
    "\n",
    "To handle the inherent probabilistic nature of LLMs, the system employs <b>self-consistency through majority voting</b> (Wang, X. et al., 2023), where multiple generations of model outputs are compared, and the most frequent result is selected for higher accuracy. This process is computationally intensive but enhances reliability. Finally, the results are aggregated in a <b>map-reduce-style framework</b>: individual product matches are mapped and recorded in a detailed matrix, then reduced into a summary DataFrame showing aggregated matches for each external product. This structured pipeline effectively combines retrieval, reasoning, and aggregation techniques, ensuring accurate and explainable product mapping while demonstrating advanced NLP and machine learning practices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af0b2c1-763d-40fc-9a32-c6d58b10b8e0",
   "metadata": {},
   "source": [
    "#### Importing Python libraries\n",
    "This script imports Python modules and libraries for the product mapping application. \n",
    "\n",
    "- <b>os:</b> Provides functionality to interact with the operating system, such as file and directory operations.\n",
    "\n",
    "- <b>subprocess:</b> Used to spawn new processes, interact with the operating system, and run shell commands.\n",
    "\n",
    "- <b>time:</b> Provides time-related functions. Commonly used for measuring execution time, delays, or timestamps.\n",
    "\n",
    "- <b>requests:</b> A popular HTTP library for making API calls or downloading data from web services.\n",
    "\n",
    "- <b>json.loads:</b> Parses JSON strings into Python objects.\n",
    "\n",
    "- <b>re:</b> Provides support for regular expressions.\n",
    "\n",
    "- <b>pandas as pd:</b> A powerful library for data manipulation and analysis.\n",
    "\n",
    "- <b>numpy as np:</b> A library for numerical computing.\n",
    "\n",
    "- <b>rank_bm25.BM25Okapi:</b> Part of the rank_bm25 library, which implements the BM25 ranking algorithm for text retrieval.\n",
    "\n",
    "- <b>joblib.Memory:</b> A caching library to save computation time by storing results of expensive functions.\n",
    "\n",
    "- <b>sentencepiece as spm:</b> A library for unsupervised text tokenization and subword modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a1196f-6c87-4309-ae84-b9cdcfd424cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "from json import loads\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from joblib import Memory\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386f46e-a9d4-471f-ac10-0aa755fb12e6",
   "metadata": {},
   "source": [
    "#### Initializing constants and the job identifier (ID)\n",
    "This Python code snippet initializes constants, generates a unique job identifier (ID), and then prints it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222d8951-1c95-48ed-9c2e-fd00ab258f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_ID: llama_3_2_17313\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 4\n",
    "N_VOTES = 3\n",
    "np.random.seed(int(time.time()))\n",
    "JOB_ID = np.random.randint(0, 100000)\n",
    "JOB_ID = f'llama_3_2_{JOB_ID}'\n",
    "print('JOB_ID:', JOB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8ca97c-413a-4a04-b0a2-90ffcf168d85",
   "metadata": {},
   "source": [
    "#### Setting pandas display options\n",
    "This Python code snippet modifies Pandas display options to ensure that when data is printed (e.g., in a Jupyter Notebook or console), all of its contents are fully visible without truncation. \n",
    "\n",
    "* pd.set_option('display.max_rows', None):\n",
    "\n",
    "  Ensures that all rows in a DataFrame are displayed without truncation. Setting it to None removes this limit.\n",
    "\n",
    "* pd.set_option('display.max_columns', None):\n",
    "\n",
    "  Ensures that all columns in a DataFrame are displayed. Setting it to None removes this limit.\n",
    "\n",
    "* pd.set_option('display.width', None):\n",
    "\n",
    "  Removes restrictions on the total width of the display, allowing the output to adapt to the actual size of the DataFrame. Without this, the output might wrap or truncate rows when the DataFrame is too wide.\n",
    "\n",
    "* pd.set_option('display.max_colwidth', None):\n",
    "\n",
    "  Ensures that the full content of each column is displayed, even if the values are very long (e.g., long strings). By default, long strings might be truncated with ellipses (...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1bb5002-8297-4ac1-9a5f-b9eb13f5b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46994e84-cba3-492d-a355-a8a2dc8a2005",
   "metadata": {},
   "source": [
    "#### Loading data\n",
    "This Python code snippet reads product information from two CSV files and extracts specific columns into lists for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad7b5b03-3e00-44cd-8ff0-13b8044f7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_product_list = pd.read_csv('Data_External.csv')[\"PRODUCT_NAME\"].tolist()\n",
    "internal_product_list = pd.read_csv('Data_Internal.csv')[\"LONG_NAME\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495f076-f069-44c9-81d4-cd80068048ef",
   "metadata": {},
   "source": [
    "#### Initializing the SentencePiece tokenizer\n",
    "This Python code checks if a SentencePiece model file (Data_Internal.model) exists; if not, it creates a model from the internal_product_list. First, it preprocesses the product names by converting them to lowercase and saving them as a text corpus (Data_Internal.txt). Then, it trains a SentencePiece model using the command-line tool spm_train with specific parameters, such as byte-pair encoding (BPE), a vocabulary size of 22,675, and full character coverage. Once the model is created, it initializes a SentencePieceProcessor for tokenization. The function tokenize(text) leverages this processor to tokenize input text into subword units after converting the text to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1895aad2-42d5-403f-ab80-b9ae27af2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Data_Internal.model\"):\n",
    "    corpus = [internal_product.lower() for internal_product in internal_product_list]\n",
    "    with open('Data_Internal.txt', 'w') as f:\n",
    "        f.write('\\n'.join(corpus)+'\\n')\n",
    "    command = 'spm_train --input=Data_Internal.txt --model_prefix=Data_Internal --vocab_size=22675 --character_coverage=1.0 --model_type=bpe'\n",
    "    subprocess.run(command.split(' ')) \n",
    "sp = spm.SentencePieceProcessor(model_file='Data_Internal.model')\n",
    "\n",
    "def tokenize(text):\n",
    "    return sp.encode(text.lower(), out_type=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a906e54-0355-44b0-850b-0c585be7ff38",
   "metadata": {},
   "source": [
    "#### Initiating the BM25 retriever\n",
    "This code creates a tokenized corpus of the product names from the internal_product_list and initializes a BM25 retrival model using the BM25Okapi class. First, it tokenizes each product name in the internal_product_list by applying the previously defined tokenize function, which uses the trained SentencePiece model to break text into subword units. The resulting list, tokenized_corpus, contains the tokenized representation of each product name. This tokenized corpus is then used to initialize the BM25Okapi object, BM25, which is a ranking algorithm commonly used in text retrieval. This setup enables efficient ranking and searching of the product names based on query relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a29bd22-73c7-4cfe-bcc9-d88a61919578",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [tokenize(internal_product) for internal_product in internal_product_list]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2f43c-5013-4893-a1cc-75507c92a156",
   "metadata": {},
   "source": [
    "#### Initializing the Llama 3.2 client\n",
    "This Python code sets up a caching mechanism for an API request function to improve efficiency and reduce redundant network calls. It defines a request function that makes POST requests to a specified URL multiple times (n) using the requests library. The function takes parameters for the url, headers, and a json payload, sends the POST request, and appends the parsed JSON responses to a list. The joblib.Memory utility is used to cache the results of the request function, storing them in a directory (./cachedir_joblib). When the same function is called with identical parameters, the cached result is returned instead of making a new API call. Finally, the url and headers are pre-defined for interacting with the Llama 3.2 REST API endpoint (https://www.lexisophy.com/api/rest/v1/chat) using JSON payloads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "268fa6b5-50cf-425b-bcbf-2b233d2fc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = './cachedir_joblib'\n",
    "memory = Memory(cachedir, verbose=0)\n",
    "\n",
    "def request(url, headers, json, n):\n",
    "    results = []\n",
    "    for _ in range(n):\n",
    "        response = requests.post(url, headers=headers, json=json)\n",
    "        result = loads(response.content)\n",
    "        results.append(result)\n",
    "    return results\n",
    "request = memory.cache(request)\n",
    "\n",
    "url = 'https://www.lexisophy.com/api/rest/v1/chat'\n",
    "headers = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a7c32-f9e8-4b8a-9534-fb685a3ce151",
   "metadata": {},
   "source": [
    "#### Loading the prompt template for bulk matching\n",
    "This Python code reads the contents of a text file named bulk_match_prompt_template_llama_3_2.txt and stores it in the variable bulk_match_prompt_template.\n",
    "\n",
    "- bulk_match_prompt_template_llama_3_2.txt:\n",
    "```\n",
    "You are asked to judge if the external product maps to an internal product. If it is a match, return TRUE, otherwise return FALSE. You are asked to provide a rationale, regardless of whether it is a match.\n",
    "Note: The match has to be exact, meaning the product manufacturer, name, and size must be identical.\n",
    "You may first normalize the long product name (e.g., DIET LIPTON GREEN TEA W/ CITRUS 20 OZ) into the manufacturer (e.g., LIPTON), name (e.g., DIET GREEN TEA WITH CITRUS), and size (e.g., 20 OZ). \n",
    "Please do not show the source code and provide the output as a table.\n",
    "\n",
    "Here are some examples:\n",
    "External_Product\tInternal_Product\tRationale\tResult\n",
    "DIET LIPTON GREEN TEA W/ CITRUS 20 OZ\tLipton Diet Green Tea with Citrus (20oz)\tManufacturer Lipton matches, name Diet Green Tea with Citrus matches, size 20oz matches.\tTRUE\n",
    "CH-CHERRY CHS CLAW DANISH 4.25 OZ\tCloverhill Cherry Cheese Bearclaw Danish (4.25oz)\tManufacturer Cloverhill (CH) matches, name Cherry Cheese Bearclaw Danish (CHERRY CHS CLAW DANISH) matches, size 4.25oz matches.\tTRUE\n",
    "Hersheys Almond Milk Choco 1.6 oz\tHersheys Milk Chocolate with Almonds (1.85oz)\tSize 1.6 oz and 1.85oz does not match.\tFALSE\n",
    "COOKIE PEANUT BUTTER 2OZ\tFamous Amos Peanut Butter Cookie (2oz)\tName does not match, one is butter, the other is cookie.\tFALSE\n",
    "\n",
    "You are now asked to judge if the external product maps to an internal product or not:\n",
    "External_Product\tInternal_Product\tRationale\tResult\n",
    "```\n",
    "\n",
    "This prompt template designs to guide a system in evaluating whether an external product maps to an internal product by applying specific criteria. \n",
    "\n",
    "1. <b>Explicit Instructions</b>\n",
    "\n",
    "   The instructions within the template are highly explicit, specifying that a match requires the manufacturer, product name, and size to be identical. Furthermore, it explains that the language model must normalize product names into components (manufacturer, name, and size) for comparison, and provide the output in a table format.\n",
    "\n",
    "2. <b>Prompting using Few-Shot Learning</b>\n",
    "\n",
    "   The use of few-shot learning is evident in the examples included within the template. By presenting several structured examples of how the comparison process should work, the template trains or conditions the system to understand the expected format and reasoning process. Few-shot prompting is a technique that enables the language model to generalize based on these examples, thereby improving its ability to produce consistent and accurate results when applied to new inputs. The inclusion of varied examples ensures the language model can handle edge cases and nuances in product matching.\n",
    "\n",
    "3. <b>Chain of Thought Technique</b>\n",
    "\n",
    "   Involves asking the language model for providing rationales to help guide its thinking and generate a more coherent and relevant response. This technique can be useful for generating more thoughtful and well-reasoned responses from language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a594b2c-2c7a-4a9a-bd25-1e6c03240046",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bulk_match_prompt_template_llama_3_2.txt','r') as f:\n",
    "    bulk_match_prompt_template = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62cb48-7f6d-432d-a3f2-bdd24cabee67",
   "metadata": {},
   "source": [
    "#### Product mapping\n",
    "This Python function, bulk_match, performs a task to map external products to internal ones by generating prompts for a language model (LLM), collecting multiple results (via majority voting for self-consistency), and determining the most accurate match between products. The function takes a task identifier and slices of external and internal product lists as input. It constructs prompts for each external-internal product pair based on the predefined template and appends them to an output file for tracking. These prompts are sent to the REST API endpoint (using the request function) multiple times (N_VOTES), simulating the generation of several possible outputs from the LLM. The responses are saved to a results file, each annotated with the corresponding choice identifier for traceability.\n",
    "\n",
    "<b>Majority Voting</b> plays a central role in improving the accuracy of results. Since LLMs are probabilistic and may produce inconsistent outputs for the same input, the function aggregates results across multiple model responses for each external-internal product pair. Each individual result is parsed into a DataFrame (res_df), and columns corresponding to each \"vote\" are added to the main DataFrame (vote_df). The final consensus is determined by selecting the most frequently occurring answer (mode) across all responses for each product pair. This process, known as self-consistency through majority voting, enhances reliability by favoring the most probable output. The final consolidated results are appended to an output file, ensuring transparency and enabling validation. This approach trades increased computational cost for improved accuracy and robustness in decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "530106f4-8ecc-4b38-8937-d571b68323c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping external products to internal ones\n",
    "def bulk_match(item):\n",
    "    task_id = item[0]\n",
    "    sliced_external_product_list = item[1]\n",
    "    sliced_internal_product_list = item[2]\n",
    "    \n",
    "    rows = []\n",
    "    for external_product in sliced_external_product_list:\n",
    "        for internal_product in sliced_internal_product_list:\n",
    "            row = f'{external_product}\\t{internal_product}\\t\\t\\n'\n",
    "            rows.append(row)\n",
    "    prompt = bulk_match_prompt_template + (''.join(rows))\n",
    "    with open(f'output/prompts_{JOB_ID}.txt', 'a') as f:\n",
    "        print(f\"Task: {task_id}\\n\\nPROMPT: {prompt}\", file=f)\n",
    "        print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "        \n",
    "    data = {'role': 'user', 'content': prompt}\n",
    "\n",
    "    results = request(url, headers, json=data, n=N_VOTES)\n",
    "\n",
    "    with open(f'output/results_{JOB_ID}.txt', 'a') as f:\n",
    "        for choice_id, result in enumerate(results):\n",
    "            print(f\"Task: {task_id}\\n\\nChoice: {choice_id}\\n\\nRESULT:\\n{result}\", file=f)\n",
    "            print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "    \n",
    "    # Using majority voting\n",
    "    SEP_PATTERN = r'\\s*\\|\\s*'\n",
    "    vote_df_data = []\n",
    "    for external_product in sliced_external_product_list:\n",
    "        for internal_product in sliced_internal_product_list:\n",
    "            vote_df_data.append([external_product, internal_product])\n",
    "    vote_df = pd.DataFrame(vote_df_data, columns=['External_Product', 'Internal_Product'])\n",
    "    for choice_id, result in enumerate(results):\n",
    "        result = result.strip('\\n')\n",
    "        rows = result.split('\\n')\n",
    "        res_df_data = []\n",
    "        for row in rows:\n",
    "            row = re.sub(r'^'+SEP_PATTERN, '', row)\n",
    "            row = re.sub(SEP_PATTERN+r'$', '', row)\n",
    "            mo = re.match(r'\\-+'+SEP_PATTERN+r'\\-+'+SEP_PATTERN+r'\\-+'+SEP_PATTERN+r'\\-+', row)\n",
    "            if mo is None:\n",
    "                cells = re.split(SEP_PATTERN, row)\n",
    "                res_df_data.append(cells)\n",
    "        res_df = pd.DataFrame(res_df_data[1:], columns=res_df_data[0])\n",
    "\n",
    "        vote_df[f'Result_{choice_id}'] = res_df['Result']\n",
    "    \n",
    "    vote_df['Result'] = vote_df.loc[:, vote_df.columns.difference(['External_Product', 'Internal_Product'])].mode(axis=1)[0]\n",
    "    \n",
    "    with open(f'output/results_{JOB_ID}.txt', 'a') as f:\n",
    "        print(f\"Task: {task_id}\\n\\nRESULT:\\n\", file=f)\n",
    "        print(vote_df, file=f)\n",
    "        print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "    \n",
    "    return vote_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790b071-aef8-448a-bacc-63fb1f49edb7",
   "metadata": {},
   "source": [
    "#### Performing map-reduce\n",
    "This Python code applies the bulk_match function to map external products to the most relevant internal products using BM25 for candidate retrieval and stores the results in vote_df_list. It constructs a list of tasks, where each task consists of a unique task_id, a single external product from external_product_list, and the top TOP_K internal products ranked by BM25 based on their similarity to the tokenized external product. The bulk_match function is then applied to each task using the map function, which iterates over the tasks and returns a list of DataFrames (vote_df_list). Each DataFrame contains the matching results for one external product, including the final decision derived from majority voting. This approach combines efficient retrieval (BM25) with robust matching logic (LLM) to handle a potentially large dataset of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aedcf38b-6f59-4973-9398-baf81f6a407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_df_list = list(map(bulk_match, [(task_id, \n",
    "                                      [external_product], \n",
    "                                      bm25.get_top_n(tokenize(external_product), internal_product_list, n=TOP_K)) \n",
    "                                      for task_id, external_product in enumerate(external_product_list)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe294f1-dd04-4c34-a1af-06797186413c",
   "metadata": {},
   "source": [
    "#### Coalescing map-reduce results\n",
    "This code organizes the matching results into a structured format:\n",
    "\n",
    "- mapping_df: A detailed matrix for analyzing the raw pairwise mapping results.\n",
    "- aggr_df: A high-level summary for each external product, listing its corresponding internal product matches or \"NULL\" if no matches are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "814f42e0-64c9-4250-b24a-5a1b1e4054a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            External_Product  \\\n",
      "0                                  5 HOUR XTRA GRAPE 1.93 OZ   \n",
      "1                                     B - PB & HONEY SAMMICH   \n",
      "2                  B - RUDY FARMS - SAUSAGE AND BISCUIT TWIN   \n",
      "3                                            BANANAS - FRESH   \n",
      "4                                    BOBOS PB&J GRAPE 2.1 OZ   \n",
      "5                            BODY ARMOR STRWBRY BANANA 16 OZ   \n",
      "6                                 BR ESPRESSO W/ CREAM 11 OZ   \n",
      "7                                Bumble Bee Tuna Salad 3.5oz   \n",
      "8                                CELSIUS ORANGE ENERGY 12 OZ   \n",
      "9                                   CELSIUS PEACH VIBE 12 OZ   \n",
      "10                                   DIET MOUNTAIN DEW 20 OZ   \n",
      "11                               DOLE STRWBRY LEMONADE 20 OZ   \n",
      "12                                DOVE BAR DARK CHOC 1.44 OZ   \n",
      "13                                        Dr Pepper 12oz Can   \n",
      "14                                F - TURKEY HAM CHS HM WRAP   \n",
      "15                        F- WHITE CASTLE BREAKFAST SANDWICH   \n",
      "16                         FAIRLIFE 2% STRAWBERRY MILK 14 OZ   \n",
      "17               FL Doritos Spicy Sweet Chili LSS 1.75oz Bag   \n",
      "18                                  GRANDMA'S MINI VN 3.7 OZ   \n",
      "19                        Haribo Gold-Bears Gummi Candy 4oz.   \n",
      "20          HY Hersheys Milk Chocolate w Almonds 1.45oz Each   \n",
      "21                           KF - NY MIXED BERRY CHSCAKE CUP   \n",
      "22                 Kraft Mac & Cheese Original Cups 2.05 oz.   \n",
      "23                                 LSS-BRIM'S BBQ PORK RINDS   \n",
      "24                                        LSS-CRUNCHY CHEETO   \n",
      "25                                    LSS-DORITOS COOL RANCH   \n",
      "26                                    LSS-FLAMIN HOT CHEETOS   \n",
      "27                             LSS-RUFFLES CHDR & SOUR CREAM   \n",
      "28                                                 M&M PLAIN   \n",
      "29                                 MF-BOSTON CREME HONEY BUN   \n",
      "30                                  MF-CHOCOLATE MINI DONUTS   \n",
      "31                             MINUTE MAID FRUIT PUNCH 20 OZ   \n",
      "32                                   MOUNTAIN DEW ZERO 20 OZ   \n",
      "33                                        ORANGE FANTA 20 OZ   \n",
      "34  Pillsbury Mini SOFT BAKED Chocolate Chip Cookies Bag 3oz   \n",
      "35                 Pillsbury Soft Baked Confetti Cookies 3oz   \n",
      "36                                        POP CHIP BBQ .8 OZ   \n",
      "37                              SKITTLES ORIG GUMMIES 5.8 OZ   \n",
      "38                      STARBUCKS DOUBLESHOT + ENG-VAN 15 OZ   \n",
      "39                               STONIES PEPR/CHS/JAL .98 OZ   \n",
      "40                             Sweet Serenity Choc Chip 3 oz   \n",
      "41                     SWEET SERENITY CHOC CHIP COOKIES 3 OZ   \n",
      "42                                  YOO HOO CHOC. 11 OZ CANS   \n",
      "\n",
      "                                         Internal_Product  \n",
      "0                                                    NULL  \n",
      "1                                                    NULL  \n",
      "2                                                    NULL  \n",
      "3                                                    NULL  \n",
      "4                                                    NULL  \n",
      "5                                                    NULL  \n",
      "6                                                    NULL  \n",
      "7             Bumble Bee Tuna Salad with Crackers (3.5oz)  \n",
      "8                                                    NULL  \n",
      "9                     Celsius Sparkling Peach Vibe (12oz)  \n",
      "10                                                   NULL  \n",
      "11                                                   NULL  \n",
      "12                       Dove Dark Chocolate Bar (1.44oz)  \n",
      "13                                                   NULL  \n",
      "14                                                   NULL  \n",
      "15                                                   NULL  \n",
      "16      Fairlife 2% Ultra Filtered Strawberry Milk (14oz)  \n",
      "17                                                   NULL  \n",
      "18                                                   NULL  \n",
      "19                                                   NULL  \n",
      "20          Hersheys Milk Chocolate with Almonds (1.45oz)  \n",
      "21                                                   NULL  \n",
      "22              Kraft Macaroni & Cheese Original (2.05oz)  \n",
      "23                                                   NULL  \n",
      "24                                                   NULL  \n",
      "25                                                   NULL  \n",
      "26                                                   NULL  \n",
      "27                                                   NULL  \n",
      "28                                                   NULL  \n",
      "29                                                   NULL  \n",
      "30                                                   NULL  \n",
      "31                                                   NULL  \n",
      "32                                                   NULL  \n",
      "33                                                   NULL  \n",
      "34       Pillsbury Mini Soft Baked Confetti Cookies (3oz)  \n",
      "35       Pillsbury Mini Soft Baked Confetti Cookies (3oz)  \n",
      "36                                                   NULL  \n",
      "37                                                   NULL  \n",
      "38             Starbucks DoubleShot Energy Caramel (15oz)  \n",
      "39                                                   NULL  \n",
      "40  Sweet Serenity Chocolate Chip Bite Size Cookies (3oz)  \n",
      "41  Sweet Serenity Chocolate Chip Bite Size Cookies (3oz)  \n",
      "42                     Yoo-hoo Chocolate Drink Can (11oz)  \n"
     ]
    }
   ],
   "source": [
    "mapping_df = pd.DataFrame(columns=external_product_list)\n",
    "mapping_df['Internal_Product'] = internal_product_list\n",
    "mapping_df.set_index('Internal_Product', inplace=True)\n",
    "\n",
    "for vote_df in vote_df_list:\n",
    "    for index, row in vote_df.iterrows():\n",
    "        mapping_df.loc[row['Internal_Product'], row['External_Product']] = row['Result']\n",
    "\n",
    "mapping_df.to_csv(f'output/mapping_raw_{JOB_ID}.csv')\n",
    "\n",
    "aggr_df = pd.DataFrame(columns=['External_Product', 'Internal_Product'])\n",
    "aggr_df['External_Product'] = external_product_list\n",
    "aggr_internal_product_list = []\n",
    "for external_product in external_product_list:\n",
    "    internal_product = mapping_df.index[mapping_df[external_product] == 'TRUE'].tolist()\n",
    "    internal_product = 'NULL' if len(internal_product) == 0 else ','.join(internal_product)\n",
    "    aggr_internal_product_list.append(internal_product)\n",
    "aggr_df['Internal_Product'] = aggr_internal_product_list\n",
    "\n",
    "with open(f'output/results_{JOB_ID}.txt', 'a') as f:   \n",
    "    print(aggr_df, file=f)\n",
    "    print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "    \n",
    "aggr_df.to_csv(f'output/mapping_aggr_{JOB_ID}.csv')\n",
    "print(aggr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d442c-aa18-4ee7-b8c2-5fbf58ee7196",
   "metadata": {},
   "source": [
    "### Approach Two: ChatGPT o1-mini\n",
    "The approach leverages the ChatGPT o1-mini to tackle a complex task of matching and coalescing product data through a streamlined, iterative process. By dividing the task into smaller, manageable components and using a structured workflow, the system efficiently processes product lists in parallel, generating intermediate outputs and incrementally refining them through majority voting and coalescing. This method demonstrates how traditionally intricate tasks, requiring extensive logic or custom algorithms, can be approached with simpler and more intuitive procedures by leveraging the reasoning and language understanding capabilities of the ChatGPT o1 family. Through prompt engineering and iterative reduction, the system achieves robust, scalable, and accurate results with reduced complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0635aa-0d11-4786-b8e3-8a93d644f2a8",
   "metadata": {},
   "source": [
    "#### Importing Python libraries\n",
    "This snippet imports concurrent.futures for managing multiple threads or processes. The openai module, specifically the OpenAI class,  interacts with OpenAI's API for tasks like natural language processing. The pandas library (pd) offers data manipulation and analysis capabilities, while numpy (np) is used for numerical computations. The time module is imported for handling time-based operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc7d46-b445-480e-8188-025df45b7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40da13-4cdd-45e8-ba82-5f9e4c00541b",
   "metadata": {},
   "source": [
    "#### Initializing constants and the job identifier (ID)\n",
    "This code initializes configuration parameters and a unique identifier for a job. The MAX_MATCHING_COUNT and MAX_COALESCING_COUNT constants set limits, for iterative product matching. N_PROC is set to 24, utilizing 24 parallel processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe1a7d-dbd5-4a53-8d02-24291b6b4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MATCHING_COUNT = 30\n",
    "MAX_COALESCING_COUNT = 20\n",
    "N_PROC = 24\n",
    "np.random.seed(int(time.time()))\n",
    "JOB_ID = np.random.randint(0, 100000)\n",
    "JOB_ID = f'o1_mini_{JOB_ID}'\n",
    "print('JOB_ID:', JOB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38c67a-5aa4-4e2c-8cf8-feec8424ac45",
   "metadata": {},
   "source": [
    "#### Initializating the OpenAI client\n",
    "This code snippet initializes an instance of the OpenAI client by passing an API key as a parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83347a-da7a-4631-9ebc-9c208e34c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5beb622-d357-4b3b-8223-7e82aa206ce9",
   "metadata": {},
   "source": [
    "#### Loading data\n",
    "This code reads product data from two CSV files, Data_External.csv and Data_Internal.csv, into Python lists using the pandas library. The first line loads the \"PRODUCT_NAME\" column from Data_External.csv and converts its values into a list, storing them in external_product_list. Similarly, the second line reads the \"LONG_NAME\" column from Data_Internal.csv and converts its values into a list, storing them in internal_product_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee603aa-70b7-470f-bac0-09b8930d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_product_list = pd.read_csv('Data_External.csv')[\"PRODUCT_NAME\"].tolist()\n",
    "internal_product_list = pd.read_csv('Data_Internal.csv')[\"LONG_NAME\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869dec27-cec8-44aa-ad9b-b9b6026e43f9",
   "metadata": {},
   "source": [
    "#### Loading the prompt template\n",
    "This code snippet reads a text file, bulk_match_prompt_template_o1_mini.txt, which contains a template for a prompt, and customizes it by dynamically inserting the external product list to the prompt.\n",
    "\n",
    "- bulk_match_prompt_template_o1_mini.txt\n",
    "```\n",
    "You are provided with two product list: one is the external product list, and the other is the internal product list.\n",
    "You are asked to create a table including all external products with the corresponding mapped internal product. If no match is found, the table should indicate NULL for the internal product. (Note: The match has to be exact, meaning the product manufacturer, name, and size must be identical.) \n",
    "Only output the table and trim any excess whitespace from the table’s output.\n",
    "\n",
    "---\n",
    "Examples:  \n",
    "To help you understand our requirements, here are a few examples of correct and wrong matches:\n",
    "Correct Matches: \n",
    "External_Product_Name \tInternal_Product_Name \n",
    "DIET LIPTON GREEN TEA W/ CITRUS 20 OZ \tLipton Diet Green Tea with Citrus (20oz) \n",
    "CH-CHERRY CHS CLAW DANISH 4.25 OZ \tCloverhill Cherry Cheese Bearclaw Danish (4.25oz) \n",
    "\n",
    "Wrong Matches:\n",
    "External_Product_Name \tInternal_Product_Name \n",
    "Hersheys Almond Milk Choco 1.6 oz \tHersheys Milk Chocolate with Almonds (1.85oz) \n",
    "COOKIE PEANUT BUTTER 2OZ \tFamous Amos Peanut Butter Cookie (2oz) \n",
    "\n",
    "---\n",
    "External Product List:\n",
    "<external_product_list>\n",
    "\n",
    "---\n",
    "Internal Product List:\n",
    "<internal_product_list>\n",
    "```\n",
    "\n",
    "The bulk_match_prompt_template_o1_mini.txt prompt demonstrates the effective use of <b>Explicit Instructions</b> and <b>Few-Shot Prompting</b> to guide a model in generating precise and accurate outputs for matching products between two lists.\n",
    "\n",
    "- Explicit Instructions\n",
    "\n",
    "  The model is explicitly instructed to \"create a table including all external products with the corresponding mapped internal product\" and to \"indicate NULL for unmatched internal products.\" The prompt specifies that the match must be exact, including product manufacturer, name, and size.\n",
    "\n",
    "- Few-Shot Prompting\n",
    "\n",
    "  The prompt uses examples of both correct and incorrect matches to demonstrate the expected behavior, which helps guide the model in producing high-quality output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0869b80-a995-4b97-9fa1-74cf13c33676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bulk_match_prompt_template_o1_mini.txt','r') as f:\n",
    "    bulk_match_prompt_template = f.read()\n",
    "bulk_match_prompt_template = bulk_match_prompt_template.replace('<external_product_list>', '\\n'.join(external_product_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db113142-efc5-44e1-ae3a-cf1ce606f824",
   "metadata": {},
   "source": [
    "#### Product mapping\n",
    "This Python code defines a function bulk_match for mapping external products to internal ones by interacting with the language model o1-mini via the OpenAI API. The function processes a task identified by task_id and customizes the matching prompt by injecting a specific internal_product_list into a predefined template. The prompt is logged into a file for traceability. The language model generates five different outputs (n=5) for each task, and these outputs are then saved to an output file.\n",
    "\n",
    "The function employs <b>self-consistency through majority voting</b> to refine the outputs generated by the model. All results from the initial generation step are combined into a single prompt explaining the concept of majority voting, where the final decision is based on the most frequently occurring outcome among the alternatives. This technique improves the reliability of the model's outputs by emphasizing consensus among multiple responses, thereby reducing errors and inconsistencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746aa99b-b057-4fd4-94e3-4809f3725e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_match(item):\n",
    "    task_id = item[0]\n",
    "    prompt = bulk_match_prompt_template.replace('<internal_product_list>', '\\n'.join(item[1]))\n",
    "    with open(f'output/prompts_{JOB_ID}.txt', 'a') as f:\n",
    "        print(f\"Task: {task_id}\\n\\nPROMPT: {prompt}\", file=f)\n",
    "        print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"o1-mini-2024-09-12\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ],\n",
    "      n=5\n",
    "    )\n",
    "    results = []\n",
    "    with open(f'output/results_{JOB_ID}.txt', 'a') as f:\n",
    "        for choice_id in range(len(completion.choices)):\n",
    "            result = completion.choices[choice_id].message.content\n",
    "            print(f\"Task: {task_id}\\n\\nChoice: {choice_id}\\n\\nRESULT: {result}\", file=f)\n",
    "            print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "            results.append(result)\n",
    "    \n",
    "    # Using majority voting\n",
    "    prompt = \"Please combine the following results using majority voting. Majority voting is a decision-making rule in which the final outcome is determined by choosing the option that receives more votes than any other alternative. Only output the table and trim any excess whitespace from the table’s output: \\n\\n---\"+(\"\\n\\n----------------------------\\n\\n\".join(results))\n",
    "    with open(f'output/prompts_{JOB_ID}.txt', 'a') as f:\n",
    "        print(f\"Task: {task_id}\\n\\nPROMPT: {prompt}\", file=f)\n",
    "        print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"o1-mini-2024-09-12\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ],\n",
    "      n=1\n",
    "    )\n",
    "    result = completion.choices[0].message.content\n",
    "    with open(f'output/results_{JOB_ID}.txt', 'a') as f:\n",
    "        print(f\"Task: {task_id}\\n\\nRESULT: {result}\", file=f)\n",
    "        print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb33f28-08f5-4537-833a-a66815a3a37f",
   "metadata": {},
   "source": [
    "#### Performing map-reduce\n",
    "This code snippet uses multithreading with the concurrent.futures.ThreadPoolExecutor to efficiently process product matching tasks in parallel. The max_workers=N_PROC parameter specifies that up to N_PROC threads (24 in this case) can run concurrently, which maximizes resource utilization for the workload. The start_indexes list is generated to partition the internal_product_list into smaller chunks, each of size MAX_MATCHING_COUNT (30 items). These chunks are then processed in parallel using the executor.map function, where the bulk_match function is applied to each partition. The input to bulk_match includes a unique task identifier (e.g., 'm-0', 'm-1') and a corresponding subset of internal_product_list. The results from all tasks are collected as a list and stored in the results variable. This approach ensures efficient processing of large datasets by breaking them into manageable pieces and distributing the work across multiple threads, significantly improving performance in API-intensive tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a402d-0f40-4d89-b1ed-255f5e1ad9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=N_PROC) as executor:\n",
    "    start_indexes = list(range(0, len(internal_product_list), MAX_MATCHING_COUNT))\n",
    "    results = list(executor.map(bulk_match, [(f'm-{index//MAX_MATCHING_COUNT}', internal_product_list[index:index+MAX_MATCHING_COUNT]) for index in start_indexes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d31d9-2c3a-4e28-b6dc-007241fd4f2d",
   "metadata": {},
   "source": [
    "#### Iteratively coalescing results\n",
    "This code implements a coalescing step to aggregate and refine the results from a map-reduce process, leveraging an iterative approach with a multithreaded executor for efficiency. The coalesce function handles individual coalescing tasks. For each task, it constructs a prompt instructing the model to merge results by selecting non-NULL values if available and defaulting to NULL when all values are NULL. The constructed prompt is logged into a file for traceability. The function then uses the OpenAI client to query the language model with the prompt and retrieves the coalesced result. This result is logged into an output file for review and returned.\n",
    "\n",
    "The iterative loop processes the list of intermediate results (results) in batches, reducing their size at each iteration. It uses a ThreadPoolExecutor with a concurrency limit of N_PROC to coalesce the results in parallel. The results are divided into chunks of size MAX_COALESCING_COUNT (20 items) using indices generated by start_indexes. For each chunk, the coalesce function is called with a unique task identifier (e.g., 'c-0-0', 'c-0-1') and a subset of results. After each iteration, the number of results decreases, and the loop continues until only one result remains, representing the fully coalesced output. This iterative reduction strategy ensures scalability and efficiency in merging large datasets while adhering to memory and performance constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c049954-c125-48b0-a70b-383c6dd14dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coalesce(item):\n",
    "    task_id = item[0]\n",
    "    with open(f'output/prompts_{JOB_ID}.txt', 'a') as f:\n",
    "        prompt = \"Please coalesce the following results. If a non-NULL value is found, use it; if all values are NULL, return NULL. Only output the table and trim any excess whitespace from the table’s output: \\n\\n---\"+(\"\\n\\n----------------------------\\n\\n\".join(item[1]))\n",
    "        print(f\"Task: {task_id}\\n\\nPROMPT: {prompt}\", file=f)\n",
    "        print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "        \n",
    "    completion = client.chat.completions.create(\n",
    "          model=\"o1-mini-2024-09-12\",\n",
    "          messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "          ],\n",
    "          n=1\n",
    "        )\n",
    "    result = completion.choices[0].message.content\n",
    "    with open(f'output/results_{JOB_ID}.txt', 'a') as f:\n",
    "        print(f\"Task: {task_id}\\n\\nRESULT: {result}\", file=f)\n",
    "        print(\"\\n\\n----------------------------\\n\\n\", file=f)\n",
    "        \n",
    "    return result\n",
    "\n",
    "j = 0\n",
    "while len(results) > 1:\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=N_PROC) as executor:\n",
    "        start_indexes = list(range(0, len(results), MAX_COALESCING_COUNT))\n",
    "        results = list(executor.map(coalesce, [(f'c-{j}-{index//MAX_COALESCING_COUNT}', results[index:index+MAX_COALESCING_COUNT]) for index in start_indexes]))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab64e13-b379-494c-b71a-5dcd689b9069",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Taku Kudo and John Richardson. 2018. SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. In <i>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</i>, pages 66–71, Brussels, Belgium. Association for Computational Linguistics.\n",
    "- Robertson, S. and Zaragoza, H., 2009. The probabilistic relevance framework: BM25 and beyond. <i>Foundations and Trends® in Information Retrieval</i>, 3(4), pp.333-389.\n",
    "- Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F. and Rodriguez, A., 2023. Llama: Open and efficient foundation language models. <i>arXiv preprint arXiv:2302.13971</i>.\n",
    "- Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. Chain-of-thought prompting elicits reasoning in large language models. In <i>Proceedings of the 36th International Conference on Neural Information Processing Systems (NIPS '22)</i>. Curran Associates Inc., Red Hook, NY, USA, Article 1800, 24824–24837.\n",
    "- Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A. and Zhou, D., 2023. Self-consistency improves chain of thought reasoning in language models. <i>The Eleventh International Conference on Learning Representations</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41131e-12aa-4bb8-8aac-7adca4831e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
